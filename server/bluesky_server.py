"""
BlueskyæŠ•ç¨¿ã‚µãƒ¼ãƒãƒ¼ v1.00
"""

import re
import logging
import sqlite3
import uvicorn
from logging.handlers import TimedRotatingFileHandler
from datetime import datetime
from typing import List, Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from atproto import Client, models
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import time
import os
import sys
import asyncio
import yt_dlp

# å®šæ•°å®šç¾©
REQUEST_TIMEOUT = 15  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰
MAX_IMAGE_SIZE_BYTES = 950 * 1024  # æœ€å¤§ç”»åƒã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
INITIAL_IMAGE_QUALITY = 85  # åˆæœŸJPEGå“è³ª
MIN_IMAGE_QUALITY = 20  # æœ€å°JPEGå“è³ª
PLAY_BUTTON_IMAGE_PATH = "assets/play-circle.png"  # å†ç”Ÿãƒœã‚¿ãƒ³ç”»åƒã®ãƒ‘ã‚¹

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ï¼ˆé‡è¦ï¼ï¼‰
script_dir = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_dir)
print(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {script_dir}")

# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
LOGS_DIR = "logs"
if not os.path.exists(LOGS_DIR):
    os.makedirs(LOGS_DIR)
    print(f"âœ… ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {LOGS_DIR}")

# ãƒ­ã‚°è¨­å®š
log_filename = os.path.join(LOGS_DIR, "server.log")

# ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆå†èª­ã¿è¾¼ã¿æ™‚ãªã©ã®é‡è¤‡é˜²æ­¢ï¼‰
if logger.hasHandlers():
    logger.handlers.clear()

# ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ä½œæˆ
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ (TimedRotatingFileHandler)
# 12æ™‚é–“ã”ã¨ã«ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯7ä¸–ä»£åˆ†ä¿å­˜
file_handler = TimedRotatingFileHandler(
    log_filename,
    when='H',
    interval=12,
    backupCount=7,
    encoding='utf-8'
)
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ (ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›)
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(formatter)
logger.addHandler(stream_handler)

logger.info("=" * 50)
logger.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_filename}")
logger.info("=" * 50)

server_start_time = time.time()

# ==================== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç† ====================
class HistoryDB:
    def __init__(self, db_path="history.db"):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS posts (
                    tweet_id TEXT PRIMARY KEY,
                    bluesky_uri TEXT,
                    bluesky_cid TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            conn.commit()

    def save_post(self, tweet_id: str, bluesky_uri: str, bluesky_cid: str):
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO posts (tweet_id, bluesky_uri, bluesky_cid)
                    VALUES (?, ?, ?)
                """, (tweet_id, bluesky_uri, bluesky_cid))
                conn.commit()
        except Exception as e:
            logger.error(f"DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def get_post(self, tweet_id: str):
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT bluesky_uri, bluesky_cid FROM posts WHERE tweet_id = ?", (tweet_id,))
                return cursor.fetchone()
        except Exception as e:
            logger.error(f"DBå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

# ã‚°ãƒ­ãƒ¼ãƒãƒ«DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
history_db = HistoryDB()

app = FastAPI(title="Twitter-IFTTT-Bluesky v1.00")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://x.com"],  # Tweetdeckã®ã¿è¨±å¯
    allow_credentials=True,
    allow_methods=["POST", "GET"],
    allow_headers=["Content-Type"],
)


class PostRequest(BaseModel):
    handle: str
    appPassword: str
    text: str
    tweetUrl: str
    author: dict
    contentType: str
    mediaUrls: List[str] = []
    videoThumbnail: Optional[str] = None
    cardShortUrl: Optional[str] = None
    facets: Optional[List[dict]] = None
    quotedTweetId: Optional[str] = None

class IFTTTRequest(BaseModel):
    handle: str
    appPassword: str
    text: str
    url: str

def compress_image_to_limit(img: Image.Image, max_size_bytes: int = MAX_IMAGE_SIZE_BYTES, initial_quality: int = INITIAL_IMAGE_QUALITY) -> bytes:
    """ç”»åƒã‚’æŒ‡å®šã‚µã‚¤ã‚ºä»¥ä¸‹ã«åœ§ç¸®"""
    if img.mode != 'RGB':
        img = img.convert('RGB')
    
    output = BytesIO()
    quality = initial_quality
    
    while quality > MIN_IMAGE_QUALITY:
        output.seek(0)
        output.truncate()
        img.save(output, format='JPEG', quality=quality)
        size = output.tell()
        
        if size <= max_size_bytes:
            break
        
        quality -= 5
        logger.info(f"ç”»åƒãŒå¤§ãã™ãã¾ã™({size} bytes)ã€‚å“è³ªã‚’{quality}ã«ä¸‹ã’ã¾ã™")
    
    output.seek(0)
    final_size = len(output.getvalue())
    logger.info(f"ç”»åƒåœ§ç¸®å®Œäº†: {final_size} bytes, quality={quality}")
    
    return output.getvalue()


def expand_short_url(short_url: str) -> str:
    """çŸ­ç¸®URL(t.co)ã‚’å±•é–‹"""
    try:
        logger.info(f"çŸ­ç¸®URLå±•é–‹: {short_url}")
        response = requests.head(short_url, allow_redirects=True, timeout=REQUEST_TIMEOUT)
        expanded_url = response.url
        logger.info(f"å±•é–‹å¾ŒURL: {expanded_url}")
        return expanded_url
    except requests.RequestException as e:
        logger.error(f"çŸ­ç¸®URLå±•é–‹ã‚¨ãƒ©ãƒ¼ (ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯): {e}")
        return short_url
    except Exception as e:
        logger.error(f"çŸ­ç¸®URLå±•é–‹ã‚¨ãƒ©ãƒ¼ (äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼): {e}", exc_info=True)
        return short_url


def expand_tco_links_in_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆå†…ã®t.coãƒªãƒ³ã‚¯ã‚’å…¨ã¦å±•é–‹"""
    tco_pattern = r'https://t\.co/[a-zA-Z0-9]+'
    
    def replace_link(match):
        tco_url = match.group(0)
        return expand_short_url(tco_url)
            
    return re.sub(tco_pattern, replace_link, text)


def extract_media_info(url: str) -> dict:
    """yt-dlpã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ã‚’æŠ½å‡º"""
    try:
        logger.info(f"ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±æŠ½å‡ºé–‹å§‹: {url}")
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True, # flatã«æˆ»ã™ (ç”»åƒãƒ„ã‚¤ãƒ¼ãƒˆã§å‹•ç”»æ¤œç´¢ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã‚’é˜²ã)
            'ignoreerrors': True, # ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ç¶šè¡Œ
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            
            if not info:
                logger.warning("yt-dlpã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return None # Noneã‚’è¿”ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã•ã›ã‚‹

            media_info = {
                'type': 'card', # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                'media_urls': [],
                'thumbnail': None,
                'text': info.get('description', ''),
                'author': {
                    'name': info.get('uploader', ''),
                    'screen_name': info.get('uploader_id', ''),
                    'avatar_url': ''
                }
            }
            
            # è¤‡æ•°ç”»åƒ (entriesãŒã‚ã‚‹å ´åˆ)
            if 'entries' in info:
                logger.info(f"è¤‡æ•°ãƒ¡ãƒ‡ã‚£ã‚¢å€™è£œã‚’æ¤œå‡º: {len(info['entries'])}ä»¶")
                images = []
                for entry in info['entries']:
                    if entry.get('thumbnail'):
                         images.append(entry['thumbnail'])
                    elif entry.get('url') and 'pbs.twimg.com' in entry.get('url'):
                         images.append(entry['url'])

                # é‡è¤‡é™¤å»
                images = list(dict.fromkeys(images))
                
                if images:
                    media_info['type'] = 'image'
                    media_info['media_urls'] = images
                    logger.info(f"ç”»åƒURLæŠ½å‡º: {len(images)}æš")
                    return media_info

            # å˜ä¸€å‹•ç”»/GIF
            if info.get('_type') == 'video' or info.get('ext') in ['mp4', 'gif'] or 'formats' in info:
                 media_info['type'] = 'video'
                 media_info['thumbnail'] = info.get('thumbnail')
                 logger.info(f"å‹•ç”»/GIFã‚’æ¤œå‡º: thumb={bool(media_info['thumbnail'])}")
                 return media_info
            
            # å˜ä¸€ç”»åƒ
            if info.get('thumbnail'):
                media_info['type'] = 'image'
                media_info['media_urls'] = [info['thumbnail']]
                logger.info("å˜ä¸€ç”»åƒã‚’æ¤œå‡º")
                return media_info
                
            logger.info("ãƒ¡ãƒ‡ã‚£ã‚¢ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return media_info

    except Exception as e:
        logger.error(f"ãƒ¡ãƒ‡ã‚£ã‚¢æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None


def fetch_ogp_data(url: str) -> dict:
    """URLã‹ã‚‰OGPæƒ…å ±ã‚’å–å¾—"""
    try:
        logger.info(f"OGPå–å¾—é–‹å§‹: {url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; Discordbot/2.0; +https://discordapp.com)'
        }
        
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        ogp_data = {
            'title': '',
            'description': '',
            'image': '',
            'url': url
        }
        
        og_title = soup.find('meta', property='og:title')
        twitter_title = soup.find('meta', attrs={'name': 'twitter:title'})
        title_tag = soup.find('title')
        
        if og_title and og_title.get('content'):
            ogp_data['title'] = og_title.get('content', '')
        elif twitter_title and twitter_title.get('content'):
            ogp_data['title'] = twitter_title.get('content', '')
        elif title_tag:
            ogp_data['title'] = title_tag.string or ''
        
        og_desc = soup.find('meta', property='og:description')
        twitter_desc = soup.find('meta', attrs={'name': 'twitter:description'})
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        
        if og_desc and og_desc.get('content'):
            ogp_data['description'] = og_desc.get('content', '')
        elif twitter_desc and twitter_desc.get('content'):
            ogp_data['description'] = twitter_desc.get('content', '')
        elif meta_desc and meta_desc.get('content'):
            ogp_data['description'] = meta_desc.get('content', '')
        
        og_image = soup.find('meta', property='og:image')
        twitter_image = soup.find('meta', attrs={'name': 'twitter:image'})
        twitter_image_src = soup.find('meta', attrs={'name': 'twitter:image:src'})
        
        image_url = ''
        if og_image and og_image.get('content'):
            image_url = og_image.get('content', '')
        elif twitter_image and twitter_image.get('content'):
            image_url = twitter_image.get('content', '')
        elif twitter_image_src and twitter_image_src.get('content'):
            image_url = twitter_image_src.get('content', '')
        
        if image_url and not image_url.startswith('http'):
            parsed = urlparse(url)
            base_url = f"{parsed.scheme}://{parsed.netloc}"
            if image_url.startswith('/'):
                image_url = base_url + image_url
            else:
                image_url = base_url + '/' + image_url
        
        ogp_data['image'] = image_url
        
        logger.info(f"OGPå–å¾—æˆåŠŸ: title='{ogp_data['title'][:50]}', image={bool(ogp_data['image'])}")
        
        return ogp_data
        
    except requests.RequestException as e:
        logger.error(f"OGPå–å¾—ã‚¨ãƒ©ãƒ¼ (ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯): {e}")
        return {
            'title': url,
            'description': '',
            'image': '',
            'url': url
        }
    except Exception as e:
        logger.error(f"OGPå–å¾—ã‚¨ãƒ©ãƒ¼ (äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼): {e}", exc_info=True)
        return {
            'title': url,
            'description': '',
            'image': '',
            'url': url
        }


def download_image(url: str) -> Image.Image:
    """ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
    try:
        logger.info(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {url}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        img = Image.open(BytesIO(response.content))
        logger.info(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {img.size}")
        return img
    except requests.RequestException as e:
        logger.error(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯): {e}")
        return None
    except Exception as e:
        logger.error(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼): {e}", exc_info=True)
        return None


def add_play_button(img: Image.Image) -> Image.Image:
    """ç”»åƒã®ä¸­å¤®ã«å†ç”Ÿãƒœã‚¿ãƒ³ã‚’åˆæˆ
    
    å¤–éƒ¨ç”»åƒãƒ•ã‚¡ã‚¤ãƒ« (play-circle.png) ã‚’ä½¿ç”¨
    ã‚µã‚¤ã‚º: 144x144pxï¼ˆå›ºå®šï¼‰
    """
    # å†ç”Ÿãƒœã‚¿ãƒ³ç”»åƒã‚’èª­ã¿è¾¼ã¿
    play_button_path = os.path.join(script_dir, PLAY_BUTTON_IMAGE_PATH)
    
    if not os.path.exists(play_button_path):
        logger.error(f"å†ç”Ÿãƒœã‚¿ãƒ³ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {play_button_path}")
        logger.warning("å†ç”Ÿãƒœã‚¿ãƒ³ãªã—ã§ç¶šè¡Œã—ã¾ã™")
        return img
    
    try:
        # å†ç”Ÿãƒœã‚¿ãƒ³ç”»åƒã‚’èª­ã¿è¾¼ã¿
        play_button = Image.open(play_button_path)
        
        # å†ç”Ÿãƒœã‚¿ãƒ³ãŒRGBAãƒ¢ãƒ¼ãƒ‰ã§ãªã„å ´åˆã¯å¤‰æ›
        if play_button.mode != 'RGBA':
            play_button = play_button.convert('RGBA')
        
        # å…ƒç”»åƒã‚’RGBAãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›
        if img.mode != 'RGBA':
            img_rgba = img.convert('RGBA')
        else:
            img_rgba = img.copy()
        
        # ç”»åƒã‚µã‚¤ã‚ºã¨ä¸­å¿ƒç‚¹
        img_width, img_height = img_rgba.size
        center_x = img_width // 2
        center_y = img_height // 2
        
        # å†ç”Ÿãƒœã‚¿ãƒ³ã®ã‚µã‚¤ã‚ºï¼ˆ144x144pxã§å›ºå®šï¼‰
        button_width, button_height = play_button.size
        
        # ç”»åƒã‚µã‚¤ã‚ºã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        # ç”»åƒã®çŸ­è¾ºã®1/4ã®ã‚µã‚¤ã‚ºã«ã™ã‚‹
        min_dimension = min(img_width, img_height)
        target_button_size = int(min_dimension / 4)
        
        # æœ€ä½ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆä»»æ„ã€ä¾‹ãˆã°32pxä»¥ä¸‹ã«ã¯ã—ãªã„ãªã©ï¼‰
        target_button_size = max(target_button_size, 32)
        
        play_button = play_button.resize((target_button_size, target_button_size), Image.LANCZOS)
        button_width, button_height = target_button_size, target_button_size
        logger.info(f"å†ç”Ÿãƒœã‚¿ãƒ³ã‚’ãƒªã‚µã‚¤ã‚º: {button_width}x{button_height}px (å…ƒç”»åƒã®çŸ­è¾º: {min_dimension}px)")
        
        # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’ä¸­å¤®ã«é…ç½®
        position = (
            center_x - button_width // 2,
            center_y - button_height // 2
        )
        
        # ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä½¿ã£ã¦åˆæˆ
        img_rgba.paste(play_button, position, play_button)
        
        # å…ƒã®ç”»åƒãƒ¢ãƒ¼ãƒ‰ãŒRGBã ã£ãŸå ´åˆã¯æˆ»ã™
        if img.mode == 'RGB':
            img_with_button = img_rgba.convert('RGB')
        else:
            img_with_button = img_rgba
        
        logger.info(f"å†ç”Ÿãƒœã‚¿ãƒ³ã‚’è¿½åŠ : {button_width}x{button_height}px at {position}")
        
        return img_with_button
        
    except Exception as e:
        logger.error(f"å†ç”Ÿãƒœã‚¿ãƒ³åˆæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        logger.warning("å†ç”Ÿãƒœã‚¿ãƒ³ãªã—ã§ç¶šè¡Œã—ã¾ã™")
        return img


def resize_and_crop(img: Image.Image, target_width: int, target_height: int) -> Image.Image:
    """ç”»åƒã‚’ç›®æ¨™ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º&ã‚¯ãƒ­ãƒƒãƒ—(ä½™ç™½ãªã—)"""
    target_ratio = target_width / target_height
    img_ratio = img.width / img.height
    
    if img_ratio > target_ratio:
        new_height = target_height
        new_width = int(new_height * img_ratio)
    else:
        new_width = target_width
        new_height = int(new_width / img_ratio)
    
    img_resized = img.resize((new_width, new_height), Image.LANCZOS)
    
    left = (new_width - target_width) // 2
    top = (new_height - target_height) // 2
    right = left + target_width
    bottom = top + target_height
    
    img_cropped = img_resized.crop((left, top, right, bottom))
    
    return img_cropped


def combine_images(image_urls: List[str], target_width: int = 800, target_height: int = 418) -> bytes:
    """è¤‡æ•°ã®ç”»åƒã‚’1ã¤ã«çµåˆ"""
    try:
        logger.info(f"ç”»åƒçµåˆé–‹å§‹: {len(image_urls)}æš")
        
        images = []
        for url in image_urls:
            img = download_image(url)
            if img:
                if img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                    img = background
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                images.append(img)
        
        if not images:
            logger.error("æœ‰åŠ¹ãªç”»åƒãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        if len(images) == 1:
            combined = resize_and_crop(images[0], target_width, target_height)
            
        elif len(images) == 2:
            half_width = target_width // 2
            
            img1 = resize_and_crop(images[0], half_width, target_height)
            img2 = resize_and_crop(images[1], half_width, target_height)
            
            combined = Image.new('RGB', (target_width, target_height))
            combined.paste(img1, (0, 0))
            combined.paste(img2, (half_width, 0))
                
        elif len(images) == 3:
            half_width = target_width // 2
            half_height = target_height // 2
            
            img1 = resize_and_crop(images[0], half_width, target_height)
            img2 = resize_and_crop(images[1], half_width, half_height)
            img3 = resize_and_crop(images[2], half_width, half_height)
            
            combined = Image.new('RGB', (target_width, target_height))
            combined.paste(img1, (0, 0))
            combined.paste(img2, (half_width, 0))
            combined.paste(img3, (half_width, half_height))
            
        else:
            images = images[:4]
            
            quarter_width = target_width // 2
            quarter_height = target_height // 2
            
            combined = Image.new('RGB', (target_width, target_height))
            
            positions = [
                (0, 0),
                (quarter_width, 0),
                (0, quarter_height),
                (quarter_width, quarter_height)
            ]
            
            for idx, (img, pos) in enumerate(zip(images, positions)):
                img_cropped = resize_and_crop(img, quarter_width, quarter_height)
                combined.paste(img_cropped, pos)
        
        # ç”»åƒåœ§ç¸®ï¼ˆå…±é€šé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        image_data = compress_image_to_limit(combined)
        
        logger.info(f"ç”»åƒçµåˆæˆåŠŸ: {combined.size}, {len(image_data)} bytes")
        return image_data
        
    except Exception as e:
        logger.error(f"ç”»åƒçµåˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None


def extract_mentions(text: str) -> list:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³(@username)ã‚’æŠ½å‡º"""
    mention_pattern = r'(?:^|\s)@([A-Za-z0-9_]+)'
    mentions = []
    
    for match in re.finditer(mention_pattern, text):
        username_start = match.start(1)
        at_position = username_start - 1
        
        if at_position > 0 and text[at_position - 1].isspace():
            start = at_position
        elif at_position == 0:
            start = 0
        else:
            start = at_position
        
        end = match.end(1)
        username = match.group(1)
        
        mentions.append({
            'start': start,
            'end': end,
            'username': username
        })
    
    return mentions


def extract_hashtags(text: str) -> list:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’æŠ½å‡º
    
    Twitterä»•æ§˜:
    - è‹±æ•°å­—ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã€CJKæ–‡å­—(æ¼¢å­—ãƒ»ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠ)
    - è¨˜å·(ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ä»¥å¤–)ã§çµ‚äº†
    """
    # CJKçµ±åˆæ¼¢å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã®ç¯„å›²ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
    # \u3040-\u309F: ã²ã‚‰ãŒãª
    # \u30A0-\u30FF: ã‚«ã‚¿ã‚«ãƒŠ
    # \u4E00-\u9FFF: CJKçµ±åˆæ¼¢å­—
    # \uFF66-\uFF9F: åŠè§’ã‚«ã‚¿ã‚«ãƒŠ
    hashtag_pattern = r'#([A-Za-z0-9_\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\uFF66-\uFF9F]+)'
    hashtags = []
    
    for match in re.finditer(hashtag_pattern, text):
        start = match.start()
        tag = match.group(1)
        
        # æœ«å°¾ã‹ã‚‰è¨˜å·ã‚’å‰Šé™¤(è‹±æ•°å­—ãƒ»ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ãƒ»CJKæ–‡å­—ä»¥å¤–)
        clean_tag = tag
        while clean_tag and not (clean_tag[-1].isalnum() or 
                                 clean_tag[-1] == '_' or 
                                 '\u3040' <= clean_tag[-1] <= '\u309F' or  # ã²ã‚‰ãŒãª
                                 '\u30A0' <= clean_tag[-1] <= '\u30FF' or  # ã‚«ã‚¿ã‚«ãƒŠ
                                 '\u4E00' <= clean_tag[-1] <= '\u9FFF' or  # æ¼¢å­—
                                 '\uFF66' <= clean_tag[-1] <= '\uFF9F'):   # åŠè§’ã‚«ãƒŠ
            clean_tag = clean_tag[:-1]
        
        if clean_tag:
            actual_end = start + 1 + len(clean_tag)  # +1 ã¯ # ã®åˆ†
            hashtags.append({
                'start': start,
                'end': actual_end,
                'tag': clean_tag
            })
    
    return hashtags


def extract_urls(text: str) -> list:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰URLã‚’æŠ½å‡º"""
    url_pattern = r'https?://[^\s]+'
    urls = []
    
    for match in re.finditer(url_pattern, text):
        start = match.start()
        end = match.end()
        url = match.group(0)
        urls.append({
            'start': start,
            'end': end,
            'url': url
        })
    
    return urls


def create_facets(text: str):
    """RichText facets ã‚’ä½œæˆ"""
    facets = []
    
    mentions = extract_mentions(text)
    for mention in mentions:
        facets.append({
            "index": {
                "byteStart": len(text[:mention['start']].encode('utf-8')),
                "byteEnd": len(text[:mention['end']].encode('utf-8'))
            },
            "features": [{
                "$type": "app.bsky.richtext.facet#link",
                "uri": f"https://twitter.com/{mention['username']}/"
            }]
        })
    
    hashtags = extract_hashtags(text)
    for ht in hashtags:
        facets.append({
            "index": {
                "byteStart": len(text[:ht['start']].encode('utf-8')),
                "byteEnd": len(text[:ht['end']].encode('utf-8'))
            },
            "features": [{
                "$type": "app.bsky.richtext.facet#tag",
                "tag": ht['tag']
            }]
        })
    
    urls = extract_urls(text)
    for url_info in urls:
        facets.append({
            "index": {
                "byteStart": len(text[:url_info['start']].encode('utf-8')),
                "byteEnd": len(text[:url_info['end']].encode('utf-8'))
            },
            "features": [{
                "$type": "app.bsky.richtext.facet#link",
                "uri": url_info['url']
            }]
        })
    
    return facets if facets else None


def upload_blob(client: Client, image_data: bytes):
    """ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’Blobã¨ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    try:
        logger.info(f"Blobã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {len(image_data)} bytes")
        blob = client.upload_blob(image_data)
        logger.info(f"Blobã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
        return blob.blob
    except Exception as e:
        logger.error(f"Blobã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None


def create_tweet_link_card(client: Client, tweet_url: str, author: dict, text: str, thumbnail_data: bytes = None):
    """ãƒ„ã‚¤ãƒ¼ãƒˆã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    try:
        thumb = None
        
        if thumbnail_data:
            thumb = upload_blob(client, thumbnail_data)
            if not thumb:
                logger.warning("ã‚µãƒ ãƒã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒãªã—ã§ç¶šè¡Œã—ã¾ã™ã€‚")
        
        title = f"{author.get('fullname', '')} ({author.get('username', '')})"
        description = text[:1000] if text else ''
        
        external = {
            "uri": tweet_url,
            "title": title[:300],
            "description": description,
        }
        
        if thumb:
            external["thumb"] = thumb
        
        embed = {
            "$type": "app.bsky.embed.external",
            "external": external
        }
        
        logger.info(f"ãƒ„ã‚¤ãƒ¼ãƒˆãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ä½œæˆæˆåŠŸ: thumb={bool(thumb)}")
        return embed
        
    except Exception as e:
        logger.error(f"ãƒ„ã‚¤ãƒ¼ãƒˆãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}", exc_info=True)
        return None


def create_external_link_card(client: Client, url: str, ogp_data: dict):
    """å¤–éƒ¨ã‚µã‚¤ãƒˆã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    try:
        thumb = None
        
        if ogp_data.get('image'):
            img = download_image(ogp_data['image'])
            if img:
                max_width = 1200
                max_height = 630
                
                if img.width > max_width or img.height > max_height:
                    ratio = min(max_width / img.width, max_height / img.height)
                    new_size = (int(img.width * ratio), int(img.height * ratio))
                    img = img.resize(new_size, Image.LANCZOS)
                    logger.info(f"OGç”»åƒã‚’ãƒªã‚µã‚¤ã‚º: {new_size}")
                
                # ç”»åƒåœ§ç¸®ï¼ˆå…±é€šé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
                image_data = compress_image_to_limit(img)
                thumb = upload_blob(client, image_data)
                
                if not thumb:
                    logger.warning("OGç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»åƒãªã—ã§ç¶šè¡Œã—ã¾ã™ã€‚")
        
        external = {
            "uri": url,
            "title": ogp_data.get('title', url)[:300],
            "description": ogp_data.get('description', '')[:1000],
        }
        
        if thumb:
            external["thumb"] = thumb
        
        embed = {
            "$type": "app.bsky.embed.external",
            "external": external
        }
        
        logger.info(f"å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ä½œæˆæˆåŠŸ: thumb={bool(thumb)}")
        return embed
        
    except Exception as e:
        logger.error(f"å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}", exc_info=True)
        return None


def count_graphemes(text: str) -> int:
    """ãƒ†ã‚­ã‚¹ãƒˆã®graphemeæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    return len(text)


def truncate_text_for_bluesky(text: str, tweet_url: str, max_graphemes: int = 300) -> tuple:
    """Blueskyã®æ–‡å­—æ•°åˆ¶é™ã«åã¾ã‚‹ã‚ˆã†ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹"""
    if count_graphemes(text) <= max_graphemes:
        return text, None
    
    suffix = "\nâ€¦Read more"
    suffix_length = count_graphemes(suffix)
    
    max_text_length = max_graphemes - suffix_length
    
    if max_text_length <= 0:
        logger.warning("ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã™ãã¾ã™")
        return text[:max_graphemes], None
    
    truncated_text = text[:max_text_length]
    truncated_text = truncated_text.rstrip()
    
    result = f"{truncated_text}{suffix}"
    
    link_text = "â€¦Read more"
    link_start_pos = len(truncated_text) + 1
    link_end_pos = link_start_pos + len(link_text)
    
    link_facet = {
        "index": {
            "byteStart": len(result[:link_start_pos].encode('utf-8')),
            "byteEnd": len(result[:link_end_pos].encode('utf-8'))
        },
        "features": [{
            "$type": "app.bsky.richtext.facet#link",
            "uri": tweet_url
        }]
    }
    
    logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ: {len(text)}æ–‡å­— â†’ {len(result)}æ–‡å­—")
    
    return result, link_facet


client_sessions = {}


def get_bluesky_client(handle: str, app_password: str) -> Client:
    """Blueskyã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—(ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å†åˆ©ç”¨)"""
    try:
        if handle in client_sessions:
            client = client_sessions[handle]
            try:
                client.app.bsky.actor.get_profile({'actor': handle})
                logger.info(f"æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å†åˆ©ç”¨: {handle}")
                return client
            except Exception as e:
                logger.warning(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æœŸé™åˆ‡ã‚Œã€å†ãƒ­ã‚°ã‚¤ãƒ³: {e}")
                del client_sessions[handle]
        
        logger.info(f"æ–°è¦ãƒ­ã‚°ã‚¤ãƒ³: {handle}")
        
        import httpx
        http_client = httpx.Client(timeout=30.0)
        
        client = Client()
        client._client = http_client
        client.login(handle, app_password)
        client_sessions[handle] = client
        return client
        
    except Exception as e:
        if hasattr(e, 'response') and e.response.status_code == 429:
            logger.error(f"âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {handle}")
            logger.error(f"ğŸ’¡ 24æ™‚é–“ã§10å›ã®ãƒ­ã‚°ã‚¤ãƒ³åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
            logger.error(f"ğŸ’¡ ãƒªã‚»ãƒƒãƒˆæ™‚åˆ»ã¾ã§å¾…ã¤ã‹ã€ã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹•ã›ãšã«é‹ç”¨ã—ã¦ãã ã•ã„")
        else:
            logger.error(f"ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        raise


@app.post("/post-to-bluesky")
async def post_to_bluesky(request: PostRequest):
    """Blueskyã«æŠ•ç¨¿ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        logger.info("-" * 50)
        clean_handle = request.handle.strip()
        clean_handle = ''.join(char for char in clean_handle if char.isprintable())
        
        logger.info(f"æŠ•ç¨¿ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡: {clean_handle}, ã‚¿ã‚¤ãƒ—: {request.contentType}")
        
        try:
            client = get_bluesky_client(clean_handle, request.appPassword)
        except Exception as e:
            if hasattr(e, 'response') and e.response.status_code == 429:
                logger.warning(f"âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                raise HTTPException(status_code=429, detail="Rate limit exceeded. Please wait for reset.")
            raise
        
        post_text = request.text
        embed = None
        truncate_facet = None
        
        if request.contentType == 'text':
            logger.info("ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ãƒ„ã‚¤ãƒ¼ãƒˆå‡¦ç†")
            embed = create_tweet_link_card(
                client,
                request.tweetUrl,
                request.author,
                request.text,
                None
            )
            
        elif request.contentType == 'image':
            logger.info("ç”»åƒä»˜ããƒ„ã‚¤ãƒ¼ãƒˆå‡¦ç†")
            combined_image = combine_images(request.mediaUrls)
            if combined_image:
                embed = create_tweet_link_card(
                    client, 
                    request.tweetUrl, 
                    request.author, 
                    request.text,
                    combined_image
                )
            
        elif request.contentType == 'video':
            logger.info("å‹•ç”»ä»˜ããƒ„ã‚¤ãƒ¼ãƒˆå‡¦ç†")
            if request.videoThumbnail:
                img = download_image(request.videoThumbnail)
                if img:
                    # å†ç”Ÿãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
                    img_with_play_button = add_play_button(img)
                    
                    output = BytesIO()
                    if img_with_play_button.mode != 'RGB':
                        img_with_play_button = img_with_play_button.convert('RGB')
                    img_with_play_button.save(output, format='JPEG', quality=90)
                    output.seek(0)
                    embed = create_tweet_link_card(
                        client,
                        request.tweetUrl,
                        request.author,
                        request.text,
                        output.getvalue()
                    )
            
        elif request.contentType == 'card':
            logger.info("ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ä»˜ããƒ„ã‚¤ãƒ¼ãƒˆå‡¦ç†")
            if request.cardShortUrl:
                expanded_url = expand_short_url(request.cardShortUrl)
                ogp_data = fetch_ogp_data(expanded_url)
                embed = create_external_link_card(client, expanded_url, ogp_data)
        
        if count_graphemes(post_text) > 300:
            logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™: {count_graphemes(post_text)} graphemes")
            post_text, truncate_facet = truncate_text_for_bluesky(post_text, request.tweetUrl)
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰facetsãŒé€ã‚‰ã‚Œã¦ããŸå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ã‚µãƒ¼ãƒãƒ¼ã§ç”Ÿæˆ
        if request.facets is not None:
            facets = request.facets
            # åˆ‡ã‚Šè©°ã‚ã‚‰ã‚ŒãŸå ´åˆã€ç¯„å›²å¤–ã®facetã‚’é™¤å¤–ãƒ»èª¿æ•´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€
            # ç°¡æ˜“çš„ã«ã€åˆ‡ã‚Šè©°ã‚ç™ºç”Ÿæ™‚ã¯ã‚µãƒ¼ãƒãƒ¼å´ã§å†ç”Ÿæˆã™ã‚‹ã‹ã€
            # ã‚ã‚‹ã„ã¯truncate_facetã ã‘è¿½åŠ ã—ã¦è¨±å®¹ã™ã‚‹ã‹ã€‚
            # ã“ã“ã§ã¯ã€åˆ‡ã‚Šè©°ã‚ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚µãƒ¼ãƒãƒ¼å´ã§å†ç”Ÿæˆã™ã‚‹æ–¹ãŒå®‰å…¨ã‹ã‚‚ã—ã‚Œãªã„ãŒã€
            # DOMãƒ™ãƒ¼ã‚¹ã®æ­£ç¢ºã•ã‚’å„ªå…ˆã™ã‚‹ãªã‚‰ã€åˆ‡ã‚Šè©°ã‚ä½ç½®ã‚ˆã‚Šå‰ã®facetã ã‘æ®‹ã™ã®ãŒãƒ™ã‚¹ãƒˆã€‚
            
            if truncate_facet:
                # åˆ‡ã‚Šè©°ã‚å¾Œã®ãƒã‚¤ãƒˆé•·
                truncated_byte_len = len(post_text.encode('utf-8')) - len("â€¦Read more".encode('utf-8'))
                # ç¯„å›²å†…ã®facetã®ã¿æ®‹ã™
                valid_facets = []
                for f in facets:
                    if f['index']['byteEnd'] <= truncated_byte_len:
                        valid_facets.append(f)
                facets = valid_facets
        else:
            facets = create_facets(post_text)
        
        if truncate_facet:
            if facets:
                facets.append(truncate_facet)
            else:
                facets = [truncate_facet]
        
        # å¼•ç”¨ãƒ„ã‚¤ãƒ¼ãƒˆå‡¦ç†
        if request.quotedTweetId:
            logger.info(f"å¼•ç”¨ãƒ„ã‚¤ãƒ¼ãƒˆå‡¦ç†: {request.quotedTweetId}")
            quoted_post = history_db.get_post(request.quotedTweetId)
            
            if quoted_post:
                logger.info("å¼•ç”¨å…ƒãƒ„ã‚¤ãƒ¼ãƒˆã®BlueskyæŠ•ç¨¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                quoted_uri, quoted_cid = quoted_post
                
                # å¼•ç”¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
                record_embed = models.AppBskyEmbedRecord.Main(
                    record=models.ComAtprotoRepoStrongRef.Main(
                        uri=quoted_uri,
                        cid=quoted_cid
                    )
                )
                
                if embed:
                    # æ—¢ã«ç”»åƒã‚„å‹•ç”»ãŒã‚ã‚‹å ´åˆã¯ RecordWithMedia ã‚’ä½¿ç”¨
                    logger.info("ãƒ¡ãƒ‡ã‚£ã‚¢ä»˜ãå¼•ç”¨æŠ•ç¨¿")
                    embed = models.AppBskyEmbedRecordWithMedia.Main(
                        media=embed,
                        record=record_embed
                    )
                else:
                    # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å ´åˆã¯ Record ã‚’ä½¿ç”¨
                    logger.info("ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å¼•ç”¨æŠ•ç¨¿")
                    embed = record_embed
            else:
                logger.warning("å¼•ç”¨å…ƒãƒ„ã‚¤ãƒ¼ãƒˆãŒBlueskyã«è»¢é€ã•ã‚Œã¦ã„ãªã„ã‹ã€è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸ã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")

        logger.info(f"æŠ•ç¨¿å®Ÿè¡Œ: text_length={len(post_text)}, graphemes={count_graphemes(post_text)}, has_embed={bool(embed)}")
        response = client.send_post(
            text=post_text,
            facets=facets,
            embed=embed
        )
        
        logger.info(f"æŠ•ç¨¿æˆåŠŸ: {response.uri}")
        
        # æŠ•ç¨¿å±¥æ­´ã‚’ä¿å­˜
        tweet_id = request.tweetUrl.split('/')[-1]
        history_db.save_post(tweet_id, response.uri, response.cid)
        
        return {
            "status": "success",
            "uri": response.uri,
            "cid": response.cid
        }
        
    except Exception as e:
        logger.error(f"æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/webhook/ifttt")
async def webhook_ifttt(request: IFTTTRequest):
    """IFTTTã‹ã‚‰ã®Webhookã‚’å—ã‘å–ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (æœ€é©åŒ–ç‰ˆ)"""
    try:
        logger.info("-" * 50)
        logger.info(f"IFTTT Webhookå—ä¿¡: {request.handle}")
        
        # 1. ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡ã‹ã‚‰æœ«å°¾ã®t.coãƒªãƒ³ã‚¯ã‚’å‰Šé™¤ (ãƒ¡ãƒ‡ã‚£ã‚¢ç”¨URLãªã©ã®ãŸã‚)
        clean_text = re.sub(r'https:\/\/t\.co\/[a-zA-Z0-9]+$', '', request.text).strip()
        if clean_text != request.text:
            logger.info(f"æœ«å°¾ã®t.coãƒªãƒ³ã‚¯ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {request.text} -> {clean_text}")
            
        # 2. æœ¬æ–‡ä¸­ã®æ®‹ã‚Šã®t.coãƒªãƒ³ã‚¯ã‚’å±•é–‹
        clean_text = expand_tco_links_in_text(clean_text)
        
        # ãƒ„ã‚¤ãƒ¼ãƒˆURLã‚’ãã®ã¾ã¾ä½¿ç”¨ (ç©ºç™½é™¤å»)
        tweet_url = request.url.strip()
        # IFTTTã®ä»•æ§˜ã§ <<< >>> ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ã®ã§é™¤å»
        tweet_url = tweet_url.replace('<<<', '').replace('>>>', '').strip()
        logger.info(f"è§£æå¯¾è±¡URL: {tweet_url}")
        
        # 3. ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ã®æŠ½å‡º (yt-dlpä½¿ç”¨)
        loop = asyncio.get_event_loop()
        media_info = await loop.run_in_executor(None, extract_media_info, tweet_url)
        
        # yt-dlpãŒå¤±æ•—ã—ãŸå ´åˆã¯OGPãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not media_info:
            logger.info("yt-dlpå¤±æ•—ã®ãŸã‚ã€OGPæƒ…å ±ã‚’ä½¿ç”¨ã—ã¾ã™")
            ogp_data = fetch_ogp_data(tweet_url)
            media_info = {
                'type': 'card',
                'media_urls': [],
                'thumbnail': ogp_data.get('image'),
                'author': {}
            }
            # OGPã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ•ç¨¿è€…æƒ…å ±ã‚’æŠ½å‡º "Name (@screen_name) on X"
            title = ogp_data.get('title', '')
            match = re.search(r'(.+?)\s\(@([A-Za-z0-9_]+)\)', title)
            if match:
                media_info['author']['name'] = match.group(1)
                media_info['author']['screen_name'] = match.group(2)
        
        content_type = media_info.get('type', 'card')
        card_short_url = tweet_url
        
        # æŠ•ç¨¿è€…æƒ…å ±ã®æ§‹ç¯‰
        author_info = {
            "name": "Unknown",
            "screen_name": "unknown",
            "avatar_url": ""
        }
        
        # å–å¾—ã§ããŸæƒ…å ±ã§ä¸Šæ›¸ã
        if media_info.get('author'):
            extracted_author = media_info['author']
            if extracted_author.get('name'):
                author_info['name'] = extracted_author['name']
            if extracted_author.get('screen_name'):
                author_info['screen_name'] = extracted_author['screen_name']
                if author_info['name'] == "Unknown":
                    author_info['name'] = author_info['screen_name']
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢ãªã—ã®å ´åˆã®ãƒ­ã‚¸ãƒƒã‚¯åˆ†å²
        if content_type == 'card':
            # æœ¬æ–‡ã‹ã‚‰URLã‚’æŠ½å‡º
            urls = extract_urls(clean_text)
            if urls:
                # URLãŒã‚ã‚‹å ´åˆ -> ãã®URLã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ (1ã¤ç›®ã‚’ä½¿ç”¨)
                target_url = urls[0]['url']
                logger.info(f"ãƒ¡ãƒ‡ã‚£ã‚¢ãªã—ãƒ»URLã‚ã‚Š: {target_url} ã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã™")
                card_short_url = target_url
            elif media_info.get('thumbnail'):
                 # URLã¯ãªã„ãŒã‚µãƒ ãƒã‚¤ãƒ«ï¼ˆOGPç”»åƒãªã©ï¼‰ãŒã‚ã‚‹å ´åˆ -> ãƒ„ã‚¤ãƒ¼ãƒˆè‡ªä½“ã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ï¼ˆç”»åƒã‚ã‚Šï¼‰
                 logger.info("ãƒ¡ãƒ‡ã‚£ã‚¢ãªã—ãƒ»URLãªã—ãƒ»ã‚µãƒ ãƒã‚¤ãƒ«ã‚ã‚Š: ãƒ„ã‚¤ãƒ¼ãƒˆã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã™")
                 card_short_url = tweet_url
            else:
                # URLã‚‚ã‚µãƒ ãƒã‚¤ãƒ«ã‚‚ãªã„å ´åˆ -> ãƒ„ã‚¤ãƒ¼ãƒˆè‡ªä½“ã®ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ (ã‚µãƒ ãƒã‚¤ãƒ«ãªã—)
                # post_to_blueskyã§ contentType='text' ã¨ã—ã¦æ‰±ã†ã“ã¨ã§ã‚µãƒ ãƒã‚¤ãƒ«ãªã—ãƒªãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ã«ãªã‚‹
                logger.info("ãƒ¡ãƒ‡ã‚£ã‚¢ãªã—ãƒ»URLãªã—ãƒ»ã‚µãƒ ãƒã‚¤ãƒ«ãªã—: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æŠ•ç¨¿ã¨ã—ã¦å‡¦ç†ã—ã¾ã™")
                content_type = 'text'
                card_short_url = None

        # PostRequestã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹ç¯‰
        post_request = PostRequest(
            handle=request.handle,
            appPassword=request.appPassword,
            text=clean_text,
            tweetUrl=tweet_url,
            author={
                "fullname": author_info['name'], # create_tweet_link_cardã§ä½¿ã‚ã‚Œã‚‹ã‚­ãƒ¼ã«åˆã‚ã›ã‚‹
                "username": author_info['screen_name'],
                "avatar_url": ""
            },
            contentType=content_type,
            mediaUrls=media_info.get('media_urls', []),
            videoThumbnail=media_info.get('thumbnail'),
            cardShortUrl=card_short_url,
            facets=None,
            quotedTweetId=None
        )
            
        # æŠ•ç¨¿ãƒ­ã‚¸ãƒƒã‚¯å‘¼ã³å‡ºã—
        return await post_to_bluesky(post_request)
        
    except Exception as e:
        logger.error(f"IFTTT Webhookã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "running",
        "service": "Twitter-IFTTT-Bluesky v1.00",
        "uptime_hours": round((time.time() - server_start_time) / 3600, 2),
        "current_log_file": log_filename
    }


@app.get("/health")
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "ok"}


if __name__ == "__main__":
    logger.info("=" * 50)
    logger.info("Twitter-IFTTT-Bluesky v1.00 èµ·å‹•")
    logger.info("URL: http://localhost:5000")
    logger.info("=" * 50)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=5000,
        log_level="info"
    )